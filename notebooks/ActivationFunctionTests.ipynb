{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaky ReLU Fprop Functionality Test Passed\n",
      "Leaky ReLU Bprop Test Passed\n"
     ]
    }
   ],
   "source": [
    "import mlp\n",
    "from mlp.test_methods import test_leaky_relu\n",
    "import numpy as np\n",
    "\n",
    "fprop_test, fprop_output, fprop_correct, \\\n",
    "bprop_test, bprop_output, bprop_correct = test_leaky_relu()\n",
    "\n",
    "assert fprop_test == 1.0, (\n",
    "'The random relu fprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(fprop_correct, fprop_output, fprop_output-fprop_correct)\n",
    ")\n",
    "\n",
    "print(\"Leaky ReLU Fprop Functionality Test Passed\")\n",
    "\n",
    "assert bprop_test == 1.0, (\n",
    "'The random relu bprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(bprop_correct, bprop_output, bprop_output-bprop_correct)\n",
    ")\n",
    "\n",
    "print(\"Leaky ReLU Bprop Test Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random ReLU Fprop Functionality Test Passed\n",
      "Random ReLU Bprop Test Passed\n"
     ]
    }
   ],
   "source": [
    "from mlp.test_methods import test_random_relu\n",
    "\n",
    "fprop_test, fprop_output, fprop_correct, \\\n",
    "bprop_test, bprop_output, bprop_correct = test_random_relu()\n",
    "assert fprop_test == 1.0, (\n",
    "'The random relu fprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(fprop_correct, fprop_output, fprop_output-fprop_correct)\n",
    ")\n",
    "\n",
    "print(\"Random ReLU Fprop Functionality Test Passed\")\n",
    "\n",
    "assert bprop_test == 1.0, (\n",
    "'The random relu bprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(bprop_correct, bprop_output, bprop_output-bprop_correct)\n",
    ")\n",
    "\n",
    "print(\"Random ReLU Bprop Test Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametric ReLU Fprop Functionality Test Passed\n",
      "Parametric ReLU Grads wrt Params Test Passed\n",
      "Parametric ReLU Bprop Test Passed\n"
     ]
    }
   ],
   "source": [
    "from mlp.test_methods import test_parametric_relu\n",
    "\n",
    "fprop_test, fprop_output, fprop_correct, \\\n",
    "bprop_test, bprop_output, bprop_correct, \\\n",
    "grads_wrt_param_test, grads_wrt_param_output, grads_wrt_param_correct = test_parametric_relu()\n",
    "\n",
    "assert fprop_test == 1.0, (\n",
    "'The parametric relu fprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(fprop_correct, fprop_output, fprop_output-fprop_correct)\n",
    ")\n",
    "\n",
    "print(\"Parametric ReLU Fprop Functionality Test Passed\")\n",
    "\n",
    "assert grads_wrt_param_test == 1.0, (\n",
    "'The parametric relu grad_wrt_param functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(grads_wrt_param_correct, grads_wrt_param_output, grads_wrt_param_output-grads_wrt_param_correct)\n",
    ")\n",
    "\n",
    "print(\"Parametric ReLU Grads wrt Params Test Passed\")\n",
    "\n",
    "assert bprop_test == 1.0, (\n",
    "'The parametric relu bprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(bprop_correct, bprop_output, bprop_output-bprop_correct)\n",
    ")\n",
    "\n",
    "print(\"Parametric ReLU Bprop Test Passed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELU Fprop Functionality Test Passed\n",
      "ELU Bprop Test Passed\n"
     ]
    }
   ],
   "source": [
    "from mlp.test_methods import test_exponential_linear_unit\n",
    "import numpy as np\n",
    "\n",
    "fprop_test, fprop_output, fprop_correct, \\\n",
    "bprop_test, bprop_output, bprop_correct = test_exponential_linear_unit()\n",
    "\n",
    "\n",
    "assert fprop_test == 1.0, (\n",
    "'The random relu fprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(fprop_correct, fprop_output, fprop_output-fprop_correct)\n",
    ")\n",
    "print(\"ELU Fprop Functionality Test Passed\")\n",
    "\n",
    "assert bprop_test == 1.0, (\n",
    "'The random relu bprop functionality test failed'\n",
    "'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    ".format(bprop_correct, bprop_output, bprop_output-bprop_correct, bprop_output/bprop_correct)\n",
    ")\n",
    "print(\"ELU Bprop Test Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "length of metavar tuple does not match nargs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\pythonanaconda\\envs\\mlp1\\lib\\argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonanaconda\\envs\\mlp1\\lib\\argparse.py\u001b[0m in \u001b[0;36m_format_args\u001b[1;34m(self, action, default_metavar)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m             \u001b[0mformats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'%s'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mget_metavar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\~\\mlpractical\\notebooks\\generate_activation_layer_test_outputs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Welcome to Conv test script'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--student_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"s1905792\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Your student id in the format \"s1905792\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pythonanaconda\\envs\\mlp1\\lib\\argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: length of metavar tuple does not match nargs"
     ]
    }
   ],
   "source": [
    "%run generate_activation_layer_test_outputs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
